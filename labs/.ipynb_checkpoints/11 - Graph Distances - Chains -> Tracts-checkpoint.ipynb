{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapefile\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractdata = pd.read_csv('../data/acs/nyc_tracts/nyc_tracts_census_geo_node.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Chain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaindata = pd.read_csv('../data/tables/chains_with_nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"../data/graphs/nyc.p\",\"rb\"))\n",
    "O = X['O']\n",
    "N = X['N']\n",
    "edges = X['edges']\n",
    "nodes = X['nodes']\n",
    "nodenames = X['nodenames']\n",
    "edgedatabase = X['edgedatabase']\n",
    "streets = X['streets']\n",
    "G = X['G']\n",
    "Nlist = X['Nlist'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tract Index List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractlist = []\n",
    "for i in range(tractdata.shape[0]):\n",
    "    tractdp = tractdata.iloc[i]\n",
    "    tract_node_name = tractdp.node_name.split(' | ')\n",
    "    tract_node_name = ' | '.join(tract_node_name[1:])\n",
    "    index = Nlist.index(tract_node_name)\n",
    "    tractlist.append(index)\n",
    "tractdata['node_index'] = tractlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chain Index List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainlist = []\n",
    "chainnames = []\n",
    "for i in range(chaindata.shape[0]):\n",
    "    chaindp = chaindata.iloc[i]\n",
    "    chain_node_name = chaindp.nodename\n",
    "    index = Nlist.index(chain_node_name)\n",
    "    chainlist.append(index)\n",
    "chaindata['indexer'] = range(chaindata.shape[0])\n",
    "chaindata['chain_address'] = chaindata['indexer'].astype(str) + ' | '  + chaindata['chain'] + ' | ' + chaindata['address'] + ' | ' + chaindata['zipcode'].astype(str)\n",
    "chainnames = np.array(chaindata['chain'].values)\n",
    "chainaddress = np.array(chaindata['chain_address'].values)\n",
    "chaindata['node_index'] = chainlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLength(path,G):\n",
    "    \n",
    "    #Compute Length\n",
    "    lengths = []\n",
    "    for i in range(len(path)-1):\n",
    "        orig = path[i]\n",
    "        dest = path[i+1]\n",
    "        weight = G[orig][dest]['weight']\n",
    "        lengths.append(weight)\n",
    "\n",
    "    #Return\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Exists in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairExists(source,target,chain,P):\n",
    "\n",
    "    #Top Level miss\n",
    "    exists = False\n",
    "    if (source not in P):\n",
    "        exists = False\n",
    "\n",
    "    #Source in top level P\n",
    "    if (source in P):\n",
    "        \n",
    "        #Get Target Items\n",
    "        target_items = P[source]\n",
    "        \n",
    "        #Loop through target items to see if they are keyed on target\n",
    "        for target_item in target_items:\n",
    "            key = list(target_item.keys())[0]\n",
    "\n",
    "            #If target is in P[source] determine whether chain occurs in target item\n",
    "            if (target == key):\n",
    "                chains,distance = target_item[key]\n",
    "                if (chain in chains):\n",
    "                    exists = True\n",
    "    \n",
    "    #Return\n",
    "    return exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepSize = 10\n",
    "# tractmesh = list(range(0,len(tractlist),stepSize))\n",
    "# chainmesh = list(range(0,len(chainlist),stepSize))\n",
    "# tractmesh[-1] = len(tractlist)\n",
    "# chainmesh[-1] = len(chainlist)\n",
    "# M = {}\n",
    "# V = np.zeros((len(tractmesh)-1,len(chainmesh)-1))\n",
    "# for i in range(len(tractmesh)-1):\n",
    "#     for j in range(len(chainmesh)-1):\n",
    "#         xstart = tractmesh[i]\n",
    "#         xend = tractmesh[i+1]\n",
    "#         ystart = chainmesh[j]\n",
    "#         yend = chainmesh[j+1]\n",
    "#         M[i,j] = (xstart,xend,ystart,yend)\n",
    "\n",
    "# X = {}\n",
    "# X['M'] = M\n",
    "# X['V'] = V\n",
    "# pickle.dump(X,open('../data/meshes/nyc_mesh.p',\"wb\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and Update Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeAndUpdate(M,V):\n",
    "    \n",
    "    #Update and Store\n",
    "    X = {}\n",
    "    X['M'] = M\n",
    "    X['V'] = V\n",
    "    pickle.dump(X,open('../data/meshes/nyc_mesh.p',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick Random Submesh and Return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickSubmesh():\n",
    "\n",
    "    #Unpack\n",
    "    X = pickle.load(open('../data/meshes/nyc_mesh.p',\"rb\"))\n",
    "    M = X['M']\n",
    "    V = X['V']\n",
    "\n",
    "    #Return -1 if V is completely filled\n",
    "    if (np.sum(V) == (V.shape[0] * V.shape[1])):\n",
    "        return (-1,-1,-1,-1),-1,-1,M,V\n",
    "        \n",
    "    #Pick Random submush\n",
    "    (posi,posj) = np.where(V < 1.0)\n",
    "    thisi = posi[np.random.randint(len(posi))]\n",
    "    thisj = posj[np.random.randint(len(posj))]\n",
    "    return M[(thisi,thisj)],thisi,thisj,M,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPaths(xs,xe,ys,ye,tractlist,chainlist,durations,G,D,P,unconnected):\n",
    "    \n",
    "    #Find Paths if necessary\n",
    "    durations = []\n",
    "    if (xs > -1):\n",
    "\n",
    "        #Loop\n",
    "        for i in range(xs,xe):\n",
    "            starttime = time.time()\n",
    "            for j in range(ys,ye):\n",
    "                if (D[i,j] == 0):\n",
    "                    \n",
    "                    #Get Source and Target Node Indices\n",
    "                    source =  tractlist[i]\n",
    "                    target = chainlist[j]\n",
    "\n",
    "                    #Try to run shortest path algorithm\n",
    "                    try:\n",
    "                        path = nx.shortest_path(G,source=source,target=target)\n",
    "                        pathlengths = computeLength(path,G)\n",
    "                    except:\n",
    "                        unconnected.append({source_index,target_index})\n",
    "                        path = []\n",
    "                        pathlengths = []\n",
    "\n",
    "                    #Find all subaths between tract and chain\n",
    "                    for p1 in range(len(path)):\n",
    "                        for p2 in range(p1+1,len(path)):\n",
    "                            source_index = path[p1]\n",
    "                            target_index = path[p2]\n",
    "                            if (source_index in tractlist):\n",
    "                                if (target_index in chainlist):\n",
    "                                    source_sub = tractlist.index(source_index)\n",
    "                                    target_sub = chainlist.index(target_index)\n",
    "                                    sub_length = np.sum(pathlengths[p1:p2])\n",
    "                                    sub_path = path[p1:p2]\n",
    "                                    D[source_sub,target_sub] = sub_length\n",
    "                                    P[source_sub] = {target_sub:sub_path}\n",
    "\n",
    "                    #Find all subaths between tract and chain (reverse)\n",
    "                    path = path[::-1]\n",
    "                    pathlengths = pathlengths[::-1]\n",
    "                    for p1 in range(len(path)):\n",
    "                        for p2 in range(p1+1,len(path)):\n",
    "                            source_index = path[p1]\n",
    "                            target_index = path[p2]\n",
    "                            if (source_index in tractlist):\n",
    "                                if (target_index in chainlist):\n",
    "                                    source_sub = tractlist.index(source_index)\n",
    "                                    target_sub = chainlist.index(target_index)\n",
    "                                    sub_length = np.sum(pathlengths[p1:p2])\n",
    "                                    D[source_sub,target_sub] = sub_length\n",
    "                                    P[source_sub] = {target_sub:sub_path}\n",
    "\n",
    "            #Stop the clock            \n",
    "            endtime = time.time()\n",
    "            durations.append(endtime-starttime)\n",
    "\n",
    "    #Return\n",
    "    return D,P,durations,unconnected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Paths with Intermediate Saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    #Get Submesh\n",
    "    (xs,xe,ys,ye),posi,posj,M,V = pickSubmesh()\n",
    "\n",
    "    #Load Intermediate\n",
    "    if (os.path.isfile('../data/paths/nyc_paths.p')):\n",
    "        X = pickle.load(open('../data/paths/nyc_paths.p',\"rb\"))\n",
    "        D = X['D']\n",
    "        P = X['P']\n",
    "        durations = X['durations']\n",
    "        unconnected = X['unconnected']\n",
    "    else:\n",
    "        unconnected = []\n",
    "        durations = []\n",
    "        D = np.zeros((len(tractlist),len(chainlist)))\n",
    "        P = {}\n",
    "\n",
    "    #Run if matrix is already more or less full\n",
    "    Dsubset = D[xs:xe,ys:ye]\n",
    "    if (np.sum(Dsubset>0) > 20):\n",
    "        print(i,'start run...')\n",
    "        print(float(np.sum(D>1)) / float(D.shape[0]*D.shape[1]) * 100.0)\n",
    "        print(float(np.sum(V) /float(V.shape[0]*V.shape[1])) * 100.0)\n",
    "\n",
    "        #Find Paths\n",
    "        D,P,durations,unconnected = findPaths(xs,xe,ys,ye,tractlist,chainlist,durations,G,D,P,unconnected)\n",
    "\n",
    "        #Store Intermediate\n",
    "        X = {}\n",
    "        X['D'] = D\n",
    "        X['P'] = P\n",
    "        X['durations'] = durations\n",
    "        X['unconnected'] = unconnected\n",
    "        pickle.dump(X,open('../data/paths/nyc_paths.p',\"wb\"))\n",
    "\n",
    "        #Update Mesh\n",
    "        V[posi,posj] = 1\n",
    "        storeAndUpdate(M,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542826\n",
      "11849045\n",
      "13.020678037765913\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(D>1))\n",
    "print(D.shape[0]*D.shape[1])\n",
    "print(100.0*float(np.sum(D>1))/float(D.shape[0]*D.shape[1]))\n",
    "#prev1 = 780317\n",
    "#prev2 = 829720\n",
    "#prev3 = 875274\n",
    "#prev4 = 991589\n",
    "#prev5 = 1015162\n",
    "#prev6 = 1170880\n",
    "#prev7 = 1542826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Node space with distance a tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "mychain = 'McDonalds'\n",
    "tractkeys = list(P.keys())\n",
    "nodeindex1 = tractkeys[0]\n",
    "for item in P[nodeindex1]:\n",
    "    nodeindex2,mychainlist,mydistance = nodeUnpacker(item)\n",
    "    node1 = N[nodeindex1]\n",
    "    node2 = N[nodeindex2]\n",
    "    elements1 = node1.split(' | ')\n",
    "    elements2 = node2.split(' | ')\n",
    "    lat1 = float(elements1[-3])\n",
    "    lng1 = float(elements1[-2])\n",
    "    lat2 = float(elements2[-3])\n",
    "    lng2 = float(elements2[-2])\n",
    "    chainindices = np.where(chainlist == nodeindex2)[0]\n",
    "    for c,chain_address in enumerate(mychainlist):\n",
    "        elements = chain_address.split(' | ')\n",
    "        data.append((lat1,lng1,lat2,lng2,chain_address,elements[1],mydistance))\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['lat1','lng1','lat2','lng2','chain+address','chain','distance']\n",
    "data = data[data['chain'] == mychain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = data['distance'].values\n",
    "data['distance_norm'] = distances / np.max(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = shapefile.Reader('../data/shapefiles/nyc_outline/nyc_outline.shp')\n",
    "streetsShapeRecs = sf.shapeRecords()\n",
    "points = np.array(streetsShapeRecs[0].shape.points)\n",
    "parts = streetsShapeRecs[0].shape.parts\n",
    "parts.append(points.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = data[['lat1','lng1']].values\n",
    "X = data[['lat2','lng2']].values\n",
    "rgb = np.zeros((X.shape[0],3))\n",
    "rgb[:,0] = data['distance_norm'].values\n",
    "rgb[:,1] = 0#data['distance_norm'].values**2\n",
    "rgb[:,2] = 1-data['distance_norm'].values\n",
    "offset = 0.02\n",
    "skip = 1\n",
    "plt.figure(figsize=(9,9))\n",
    "for i in range(len(parts)-1):\n",
    "    spos = parts[i]\n",
    "    epos = parts[i+1]\n",
    "    polygon = points[spos:epos,:]\n",
    "    plt.plot(polygon[:,0],polygon[:,1],c='w',linewidth=1);\n",
    "plt.scatter(X[:,0],X[:,1],c=rgb[:,:],s=60)\n",
    "plt.scatter(B[0,0],B[0,1],c='w',s=60)\n",
    "minval = np.min(np.concatenate((B[:1,:],X),axis=0),axis=0)\n",
    "maxval = np.max(np.concatenate((B[:1,:],X),axis=0),axis=0)\n",
    "plt.axis((minval[0]-offset,maxval[0]+offset,minval[1]-offset,maxval[1]+offset));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Found Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = []\n",
    "tractkeys = list(P.keys())\n",
    "for key in tractkeys:\n",
    "    index = np.where(tractlist == key)[0][0]\n",
    "    tractdp = tractdata.iloc[index]\n",
    "    lat = tractdp.lat\n",
    "    lng = tractdp.lng\n",
    "    tracts.append((lat,lng,tractdp.geoid))\n",
    "tracts = pd.DataFrame(tracts)\n",
    "tracts.columns = ['lat','lng','geoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = []\n",
    "tractkeys = list(P.keys())\n",
    "indices = []\n",
    "for key in tractkeys:\n",
    "    items = P[key]\n",
    "    for item in items:\n",
    "        nodeindex,mychainlist,mydistance = nodeUnpacker(item)\n",
    "        for mychain in mychainlist:\n",
    "            elements = mychain.split(' | ')\n",
    "            index = int(elements[0])\n",
    "            indices.append(index)\n",
    "            chaindp = chaindata.iloc[index]\n",
    "            lat = chaindp.lat\n",
    "            lng = chaindp.lng\n",
    "            chains.append((lat,lng,chaindp.chain))\n",
    "chains = pd.DataFrame(chains)\n",
    "chains.columns = ['lat','lng','node']\n",
    "chains = chains.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tract Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = shapefile.Reader('../data/acs/nyc_tracts/nyc_tracts_cleaned.shp')\n",
    "tractsShapeRecs = sf.shapeRecords()\n",
    "plist = []\n",
    "for i in range(len(tractsShapeRecs)):\n",
    "    tractpoints = np.array(tractsShapeRecs[i].shape.points)\n",
    "    tractparts = tractsShapeRecs[i].shape.parts\n",
    "    tractparts.append(tractpoints.shape[0])\n",
    "    plist.append((tractpoints,tractparts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Tracts and Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tracts[['lng','lat']].values\n",
    "C = chains[['lng','lat']].values\n",
    "rgb = np.zeros((X.shape[0],3))\n",
    "offset = 0.02\n",
    "skip = 1\n",
    "plt.figure(figsize=(9,9))\n",
    "for m in range(len(plist)):\n",
    "    tractpoints,tractparts = plist[m]\n",
    "    for i in range(len(tractparts)-1):\n",
    "        spos = tractparts[i]\n",
    "        epos = tractparts[i+1]\n",
    "        polygon = tractpoints[spos:epos,:]\n",
    "        plt.plot(polygon[:,0],polygon[:,1],c='w',linewidth=0.5,zorder=1)\n",
    "plt.scatter(X[:,0],X[:,1],c='r',s=10,zorder=2)\n",
    "plt.scatter(C[:,0],C[:,1],c='g',s=10,zorder=3)\n",
    "minval = np.min(X,axis=0)\n",
    "maxval = np.max(X,axis=0)\n",
    "plt.axis((minval[0]-offset,maxval[0]+offset,minval[1]-offset,maxval[1]+offset));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "X['P'] = P\n",
    "X['D'] = D\n",
    "pickle.dump(X,open('../data/paths/nyc_tracts_nodes.p',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
